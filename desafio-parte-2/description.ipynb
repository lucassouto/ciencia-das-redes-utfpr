{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Desafio – Parte 2 (DES_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A princípio apliquei técnicas que usavam somente **a topologia da rede** para determinar as ligações dos nós a serem avaliados, mas com essas técnicas não obtive uma boa acurácia.\n",
    "Alguns exemplos que testei:\n",
    "- Node2Vec\n",
    "- Common Neighbors\n",
    "- Jaccard Coefficient\n",
    "- Preferential Attachment\n",
    "- Random Walks\n",
    "\n",
    "Consegui resultados relativamente bons com alguns desses algoritmos, mas como queria usar os atributos dos nós e das arestas implementei uma solução usando Redes Neurais. Comecei testando somente as features de distância geográfica, o que ficou bem próximo de alguns dos algoritmos que citei anteriormente.\n",
    "Ao longo do processo, fui melhorando o treinamento com mais features e, no fim, utilizei todos os atributos dos nós e o da aresta sobre as features:\n",
    "\n",
    "- Distance: foi calculada a partir dos atributos latitude e longitude, a feature é o valor em quilômetros da distância dois nós;\n",
    "- Category Intersection: a intersecção entre as categorias dos nós;\n",
    "- Category Union: a união entre as categorias dos nós;\n",
    "- Stars: não foi feita nenhuma tratativa sobre esse dado em relação ao que existe nos próprios nós, somente os valores de cada nó foram adicionados no array;\n",
    "- Review Count: não foi feita nenhuma tratativa sobre esse dado em relação ao que existe nos próprios, somente os valores de cada nó foram adicionados no array;\n",
    "- Edge Weight: um valor 0 ou 1 indicando se peso da aresta é “relevante” ou não. Para esse caso foi feita uma validação para considerar que a aresta é relevante apenas se ela tiver um peso maior que 3, pois a grande maioria da rede é menor que isso, o que causou problemas quando treinei o modelo.\n",
    "\n",
    "No fim, notei que nem todas essas features causaram um grande efeito no treinamento do modelo. As que mais se destacaram foram as de categoria: Intersection e Union, stars e review count.\n",
    "Já a distância e o peso da aresta não mudaram muito a acurácia, mas ajudaram a chegar na melhor previsão que tive.\n",
    "Quando o modelo foi treinado usando somente as ligações existentes, a acurácia não teve muito sucesso, mas, ao adicionar features entre nós que não se ligam, consegui treinar o modelo da maneira desejada. Ao definir a classe do dataset, o len ficou a quantidade de arestas * 2 justamente para metade do treinamento ter dados de nós que não se conectam.\n",
    "```python\n",
    "    def __len__(self):\n",
    "        return len(self.edges) * 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.edges):\n",
    "            node1, node2 = self.edges[idx]\n",
    "            label = int(self.graph.has_edge(node1, node2))\n",
    "        else:\n",
    "            node1, node2 = self.random_node, self.random_node\n",
    "            while self.graph.has_edge(node1, node2):\n",
    "                node1, node2 = self.random_node, self.random_node\n",
    "            label = 0\n",
    "\n",
    "        features = extract_features(node1=node1, node2=node2, label=label)\n",
    "        return features, label\n",
    "```\n",
    "Em relação ao treinamento do modelo, usei os seguintes hiperparâmetros:\n",
    "- learning_rate = 0.001\n",
    "- num_epochs = 1000\n",
    "- criterion = nn.BCELoss()\n",
    "- optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "Esses valores foram testados e alterados por várias iterações de acurácia e foi com eles que obtive um melhor resultado. Alguns exemplos de outros parâmetros que usei:\n",
    "\n",
    "- **criterion**:\n",
    "    - MSELoss\n",
    "    - CTCLoss\n",
    "    - CrossEntropyLoss\n",
    "- **optimizer**:\n",
    "    - Adam\n",
    "    - LBFGS\n",
    "    - SGD\n",
    "- **learning_rate**:\n",
    "    - 0,1\n",
    "    - 0,01\n",
    "    - 0,0001\n",
    "- **num_epochs**:\n",
    "    - 10\n",
    "    - 100\n",
    "    - 10000\n",
    "    - 100000\n",
    "\n",
    "Critetion, optimizer e learning_rate foram os que mais mudaram a acurácia dos resultados. Já as epochs pouco influenciaram, mesmo em baixos e altos valores (10~100000).\n",
    "\n",
    "A acurácia ficou em torno de <code>0.80~0.82</code> e os dois melhores resultados que obtive no Kaggle foram: <code>0.82666 e 0.82333</code>. Os CSVs com os dois melhores resultados do Kaggle estão no diretório <code>kaggle_results</code>:\n",
    "```\n",
    "desafio-parte-2\n",
    "└── kaggle_results\n",
    "    ├── resultados__0.82333.csv\n",
    "    └── resultados__0.82666.csv\n",
    "```\n",
    "Por fim, a solução utilizou redes neurais e corresponde ao código que envio nesse desafio.\n",
    "\n",
    "Para instalar as dependências localmente e rodar o notebook utilize o poetry e python 3.11.\n",
    "```bash\n",
    "pip install -U pip\n",
    "pip install poetry\n",
    "poetry install\n",
    "```\n",
    "\n",
    "Isso vai criar uma virtualenv para que seja usado no kernel do Jupyter."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
