{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstração - Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#Inicialização diretamente com dados - tipo inferido automaticamente\n",
    "data = [[1, 2],[3, 4]]\n",
    "\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)\n",
    "\n",
    "#Inicialização de um NumPy array\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cria tensor com shape específico e com valores 1.\n",
    "#Shape (2, 3)\n",
    "ones_tensor = torch.ones(2,3)\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cria tensor com shape específico e com valores 0.\n",
    "#Shape (3, 5)\n",
    "zeros_tensor = torch.zeros(3,5)\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenação de tensors\n",
    "torch.cat([ones_tensor, ones_tensor], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.],\n",
       "        [2., 2., 2.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiplicação de tensors\n",
    "\n",
    "ones_tensor * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.3293, -0.4395,  1.4051],\n",
      "        [-1.1878, -0.7769,  0.9488],\n",
      "        [-0.0221, -0.7221, -0.1790],\n",
      "        [-0.1695,  0.1977, -0.6961],\n",
      "        [-0.8274,  0.2810, -0.4583],\n",
      "        [-0.2433,  0.6065,  0.0471],\n",
      "        [ 0.1717, -0.6669, -1.4048],\n",
      "        [-0.2413,  0.0860,  0.4311],\n",
      "        [ 0.2447,  0.7936, -0.0520],\n",
      "        [ 0.3417, -1.9973,  1.4129]])\n",
      "tensor([[ 1.4347, -0.9051],\n",
      "        [-0.6299,  1.8178],\n",
      "        [-0.5354,  0.6717],\n",
      "        [ 1.5781, -0.4787],\n",
      "        [ 0.7926, -1.5036],\n",
      "        [ 0.3670,  0.8423],\n",
      "        [-1.2824, -0.8437],\n",
      "        [ 0.5923,  1.0103],\n",
      "        [-0.2068, -0.2170],\n",
      "        [ 1.6224,  0.1875]])\n"
     ]
    }
   ],
   "source": [
    "# Cria tensor com shape específico e com valores aleaórios.\n",
    "\n",
    "#Shape (10, 3)\n",
    "x = torch.randn(10, 3)\n",
    "print(x)\n",
    "\n",
    "#Shape(10, 2)\n",
    "y = torch.randn(10, 2)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do tensor: torch.Size([10, 3])\n",
      "Datatype do tensor: torch.float32\n",
      "Dispositivo onde o tensor está armazenado: cpu\n"
     ]
    }
   ],
   "source": [
    "#Atributos de um tensor\n",
    "\n",
    "print(f\"Shape do tensor: {x.shape}\")\n",
    "print(f\"Datatype do tensor: {x.dtype}\")\n",
    "print(f\"Dispositivo onde o tensor está armazenado: {x.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo onde o tensor está armazenado: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Movendo o tensor para a GPU se disponível \n",
    "if torch.cuda.is_available():\n",
    "    x = x.to('cuda')\n",
    "    \n",
    "print(f\"Dispositivo onde o tensor está armazenado: {x.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulação de tensor \n",
    "\n",
    "As operações são similares a um Np-array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.3293, -0.4395,  1.4051],\n",
      "        [-1.1878, -0.7769,  0.9488],\n",
      "        [-0.0221, -0.7221, -0.1790],\n",
      "        [-0.1695,  0.1977, -0.6961],\n",
      "        [-0.8274,  0.2810, -0.4583],\n",
      "        [-0.2433,  0.6065,  0.0471],\n",
      "        [ 0.1717, -0.6669, -1.4048],\n",
      "        [-0.2413,  0.0860,  0.4311],\n",
      "        [ 0.2447,  0.7936, -0.0520],\n",
      "        [ 0.3417, -1.9973,  1.4129]], device='cuda:0')\n",
      "\n",
      "Primeira linha:  tensor([ 2.3293, -0.4395,  1.4051], device='cuda:0')\n",
      "Primeira coluna:  tensor([ 2.3293, -1.1878, -0.0221, -0.1695, -0.8274, -0.2433,  0.1717, -0.2413,\n",
      "         0.2447,  0.3417], device='cuda:0')\n",
      "Ultima coluna: tensor([ 1.4051,  0.9488, -0.1790, -0.6961, -0.4583,  0.0471, -1.4048,  0.4311,\n",
      "        -0.0520,  1.4129], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print()\n",
    "print('Primeira linha: ', x[0,:])\n",
    "print('Primeira coluna: ', x[:, 0])\n",
    "print('Ultima coluna:', x[:, -1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui é apresentado um exemplo simples que utiliza uma camada completamente conectada.\n",
    "\n",
    "Para acelerar as operações na rede neural, nós a movemos para a GPU, se disponível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      "tensor([[-0.4498,  0.3692, -0.4609],\n",
      "        [-0.0666,  0.4990,  0.1641]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([0.0682, 0.2553], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Construi uma camada fully connected\n",
    "#torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
    "linear = nn.Linear(3, 2)\n",
    "\n",
    "print ('w: ', linear.weight)\n",
    "print ('b: ', linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando cuda\n"
     ]
    }
   ],
   "source": [
    "# Pega a GPU ou CPU para treinamento.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Usando {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7893,  0.1114],\n",
       "        [-0.1216,  0.1024],\n",
       "        [-0.1060, -0.1330],\n",
       "        [ 0.5382,  0.2510],\n",
       "        [ 0.7553,  0.3754],\n",
       "        [ 0.3798,  0.5819],\n",
       "        [ 0.3922, -0.3195],\n",
       "        [ 0.0098,  0.3850],\n",
       "        [ 0.2750,  0.6265],\n",
       "        [-1.4740, -0.5323]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = linear.to(device)\n",
    "\n",
    "x = x.to(device)\n",
    "\n",
    "#Operação - Forward.\n",
    "pred = linear(x)\n",
    "pred\n",
    "\n",
    "#x, tensor criado acima, representa as features de entrada\n",
    "#y, tensor criado acima, representa os valores alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constroi a função de perda e otimização \n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Otimizador\n",
    "optimizer = torch.optim.Adam(linear.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perda:  1.7766430377960205\n",
      "Perda depois de 1 passo de otimização :  1.736383080482483\n",
      "Perda depois de 2 passos de otimização :  1.6982431411743164\n"
     ]
    }
   ],
   "source": [
    "#Manda o y para a gpu\n",
    "y = y.to(device)\n",
    "\n",
    "# Computa a perda.\n",
    "loss = criterion(pred, y)\n",
    "print('Perda: ', loss.item())\n",
    "\n",
    "# Propaga os erros (backpropagation) e atualiza os pesos\n",
    "loss.backward()\n",
    "optimizer.step() # 1-passo do 'gradient descent'\n",
    "\n",
    "# Imprime a perda depois de 1 passo do gradient descent.\n",
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('Perda depois de 1 passo de otimização : ', loss.item())\n",
    "\n",
    "#Mais um passo - backpropagation e atualização de pesos\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Imprime a perda depois de 2 passos do gradient descent.\n",
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('Perda depois de 2 passos de otimização : ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Um exemplo mais completo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrega os dados e os separa em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([140, 3])\n",
      "torch.Size([140])\n",
      "torch.Size([60, 3])\n",
      "torch.Size([60])\n",
      "1\n",
      "torch.float64\n",
      "\n",
      "Depois da conversão para float e do reshape\n",
      "torch.float32\n",
      "torch.Size([140, 1])\n",
      "torch.Size([60, 1])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dfPropaganda = pd.read_csv('Advertising.csv',index_col=0)\n",
    "\n",
    "y= dfPropaganda.loc[:,'Sales']\n",
    "X = dfPropaganda.loc[:,['TV','Radio','Newspaper']]\n",
    "\n",
    "y_tensor = torch.tensor(y.to_numpy())\n",
    "X_tensor = torch.tensor(X.to_numpy())\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X_tensor, y_tensor, test_size = 0.30, random_state=5)\n",
    "\n",
    "print(X_treino.shape)\n",
    "print(y_treino.shape)\n",
    "\n",
    "print(X_teste.shape)\n",
    "print(y_teste.shape)\n",
    "print(y_teste.ndim)\n",
    "print(X_treino.dtype)\n",
    "\n",
    "#Manda para o dispositivo selecionado - no caso, GPU\n",
    "X_treino = X_treino.float().to(device)\n",
    "y_treino = y_treino.float().to(device)\n",
    "\n",
    "#reshape com -1: infere o valor com base no que está sendo passado (passo para sair de 1d e ir para 2d e evitar problemas de cálculos).\n",
    "y_treino = torch.reshape(y_treino, (-1,1))\n",
    "\n",
    "X_teste = X_teste.float().to(device)\n",
    "y_teste = y_teste.float().to(device)\n",
    "y_teste = torch.reshape(y_teste, (-1,1))\n",
    "\n",
    "print(\"\\nDepois da conversão para float e do reshape\")\n",
    "print(X_treino.dtype)\n",
    "print(y_treino.shape)\n",
    "print(y_teste.shape)\n",
    "print(y_teste.ndim)\n",
    "\n",
    "#Já convertemos para float para, pois inicialmente o padrão é double'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementa uma classe com o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para definir uma rede neural em PyTorch, criamos uma classe que herda de nn.Module. Definimos as camadas da rede na função __init__ e especificamos como os dados passarão pela rede na função forward. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(torch.nn.Module):\n",
    "    \n",
    "        #Esta função é onde você define as camadas totalmente conectadas em sua rede neural\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward, self).__init__()\n",
    "            \n",
    "            \n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            \n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc3 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc4 = torch.nn.Linear(self.hidden_size, 1)\n",
    "            \n",
    "        \n",
    "        #Forward: Especifica como os dados passarão pelo seu modelo\n",
    "        #x representa nossos dados\n",
    "        def forward(self, x):\n",
    "            \n",
    "            output = self.fc1(x)\n",
    "            output = F.relu(output)\n",
    "            \n",
    "            \n",
    "            output = self.fc2(output)\n",
    "            output = F.relu(output)\n",
    "            \n",
    "            output = self.fc3(output)\n",
    "            output = F.relu(output)\n",
    "            \n",
    "            output = self.fc4(output)\n",
    "\n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo e critério de otimização\n",
    "Para acelerar as operações na rede neural, nós a movemos para a GPU, se disponível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedforward(\n",
      "  (fc1): Linear(in_features=3, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (fc4): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#input = 3 (número de features), e hidden size = 10 (número de neurôneos na camada escondida)\n",
    "model = Feedforward(3, 10).to(device)\n",
    "print(model)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino e teste do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 3])\n",
      "Teste - perda antes do treinamento 155.60873413085938\n",
      "Epoch 0: perda treino: 157.69883728027344\n",
      "Epoch 1: perda treino: 155.8976287841797\n",
      "Epoch 2: perda treino: 154.0786895751953\n",
      "Epoch 3: perda treino: 152.23849487304688\n",
      "Epoch 4: perda treino: 150.38320922851562\n",
      "Epoch 5: perda treino: 148.51319885253906\n",
      "Epoch 6: perda treino: 146.61959838867188\n",
      "Epoch 7: perda treino: 144.70167541503906\n",
      "Epoch 8: perda treino: 142.7581787109375\n",
      "Epoch 9: perda treino: 140.7838897705078\n",
      "Epoch 10: perda treino: 138.77272033691406\n",
      "Epoch 11: perda treino: 136.72340393066406\n",
      "Epoch 12: perda treino: 134.6379852294922\n",
      "Epoch 13: perda treino: 132.50711059570312\n",
      "Epoch 14: perda treino: 130.315185546875\n",
      "Epoch 15: perda treino: 128.07656860351562\n",
      "Epoch 16: perda treino: 125.79478454589844\n",
      "Epoch 17: perda treino: 123.47176361083984\n",
      "Epoch 18: perda treino: 121.1032943725586\n",
      "Epoch 19: perda treino: 118.68019104003906\n",
      "Epoch 20: perda treino: 116.20672607421875\n",
      "Epoch 21: perda treino: 113.68379211425781\n",
      "Epoch 22: perda treino: 111.11302947998047\n",
      "Epoch 23: perda treino: 108.49224090576172\n",
      "Epoch 24: perda treino: 105.8203125\n",
      "Epoch 25: perda treino: 103.09555053710938\n",
      "Epoch 26: perda treino: 100.32250213623047\n",
      "Epoch 27: perda treino: 97.50788116455078\n",
      "Epoch 28: perda treino: 94.65084838867188\n",
      "Epoch 29: perda treino: 91.75761413574219\n",
      "Epoch 30: perda treino: 88.82890319824219\n",
      "Epoch 31: perda treino: 85.87301635742188\n",
      "Epoch 32: perda treino: 82.89222717285156\n",
      "Epoch 33: perda treino: 79.88658142089844\n",
      "Epoch 34: perda treino: 76.86137390136719\n",
      "Epoch 35: perda treino: 73.82036590576172\n",
      "Epoch 36: perda treino: 70.76626586914062\n",
      "Epoch 37: perda treino: 67.70960235595703\n",
      "Epoch 38: perda treino: 64.65767669677734\n",
      "Epoch 39: perda treino: 61.615055084228516\n",
      "Epoch 40: perda treino: 58.586814880371094\n",
      "Epoch 41: perda treino: 55.578575134277344\n",
      "Epoch 42: perda treino: 52.593448638916016\n",
      "Epoch 43: perda treino: 49.63422775268555\n",
      "Epoch 44: perda treino: 46.703739166259766\n",
      "Epoch 45: perda treino: 43.80128479003906\n",
      "Epoch 46: perda treino: 40.92693328857422\n",
      "Epoch 47: perda treino: 38.096981048583984\n",
      "Epoch 48: perda treino: 35.3170166015625\n",
      "Epoch 49: perda treino: 32.581809997558594\n",
      "Epoch 50: perda treino: 29.94007682800293\n",
      "Epoch 51: perda treino: 27.419883728027344\n",
      "Epoch 52: perda treino: 25.035266876220703\n",
      "Epoch 53: perda treino: 22.802703857421875\n",
      "Epoch 54: perda treino: 20.73472785949707\n",
      "Epoch 55: perda treino: 18.84397315979004\n",
      "Epoch 56: perda treino: 17.139558792114258\n",
      "Epoch 57: perda treino: 15.628585815429688\n",
      "Epoch 58: perda treino: 14.31556224822998\n",
      "Epoch 59: perda treino: 13.20149040222168\n",
      "Epoch 60: perda treino: 12.282439231872559\n",
      "Epoch 61: perda treino: 11.55180835723877\n",
      "Epoch 62: perda treino: 11.000143051147461\n",
      "Epoch 63: perda treino: 10.61474609375\n",
      "Epoch 64: perda treino: 10.377687454223633\n",
      "Epoch 65: perda treino: 10.269914627075195\n",
      "Epoch 66: perda treino: 10.265893936157227\n",
      "Epoch 67: perda treino: 10.339094161987305\n",
      "Epoch 68: perda treino: 10.463373184204102\n",
      "Epoch 69: perda treino: 10.61314868927002\n",
      "Epoch 70: perda treino: 10.765094757080078\n",
      "Epoch 71: perda treino: 10.899632453918457\n",
      "Epoch 72: perda treino: 11.001908302307129\n",
      "Epoch 73: perda treino: 11.061957359313965\n",
      "Epoch 74: perda treino: 11.07517147064209\n",
      "Epoch 75: perda treino: 11.041110038757324\n",
      "Epoch 76: perda treino: 10.963164329528809\n",
      "Epoch 77: perda treino: 10.847332000732422\n",
      "Epoch 78: perda treino: 10.701504707336426\n",
      "Epoch 79: perda treino: 10.534287452697754\n",
      "Epoch 80: perda treino: 10.354626655578613\n",
      "Epoch 81: perda treino: 10.171436309814453\n",
      "Epoch 82: perda treino: 9.991978645324707\n",
      "Epoch 83: perda treino: 9.820394515991211\n",
      "Epoch 84: perda treino: 9.660703659057617\n",
      "Epoch 85: perda treino: 9.515037536621094\n",
      "Epoch 86: perda treino: 9.385698318481445\n",
      "Epoch 87: perda treino: 9.272208213806152\n",
      "Epoch 88: perda treino: 9.174171447753906\n",
      "Epoch 89: perda treino: 9.089942932128906\n",
      "Epoch 90: perda treino: 9.016828536987305\n",
      "Epoch 91: perda treino: 8.952544212341309\n",
      "Epoch 92: perda treino: 8.894806861877441\n",
      "Epoch 93: perda treino: 8.840919494628906\n",
      "Epoch 94: perda treino: 8.789302825927734\n",
      "Epoch 95: perda treino: 8.737485885620117\n",
      "Epoch 96: perda treino: 8.683852195739746\n",
      "Epoch 97: perda treino: 8.627567291259766\n",
      "Epoch 98: perda treino: 8.567655563354492\n",
      "Epoch 99: perda treino: 8.503944396972656\n",
      "Epoch 100: perda treino: 8.435888290405273\n",
      "Epoch 101: perda treino: 8.362740516662598\n",
      "Epoch 102: perda treino: 8.28501033782959\n",
      "Epoch 103: perda treino: 8.203310012817383\n",
      "Epoch 104: perda treino: 8.117977142333984\n",
      "Epoch 105: perda treino: 8.028769493103027\n",
      "Epoch 106: perda treino: 7.935647010803223\n",
      "Epoch 107: perda treino: 7.83746862411499\n",
      "Epoch 108: perda treino: 7.734334945678711\n",
      "Epoch 109: perda treino: 7.624670505523682\n",
      "Epoch 110: perda treino: 7.5137434005737305\n",
      "Epoch 111: perda treino: 7.403104782104492\n",
      "Epoch 112: perda treino: 7.296585559844971\n",
      "Epoch 113: perda treino: 7.1973443031311035\n",
      "Epoch 114: perda treino: 7.107152462005615\n",
      "Epoch 115: perda treino: 7.026839256286621\n",
      "Epoch 116: perda treino: 6.95155143737793\n",
      "Epoch 117: perda treino: 6.883245944976807\n",
      "Epoch 118: perda treino: 6.819444179534912\n",
      "Epoch 119: perda treino: 6.7560505867004395\n",
      "Epoch 120: perda treino: 6.690784454345703\n",
      "Epoch 121: perda treino: 6.6197509765625\n",
      "Epoch 122: perda treino: 6.542666435241699\n",
      "Epoch 123: perda treino: 6.4604315757751465\n",
      "Epoch 124: perda treino: 6.3745269775390625\n",
      "Epoch 125: perda treino: 6.286625385284424\n",
      "Epoch 126: perda treino: 6.200552463531494\n",
      "Epoch 127: perda treino: 6.117089748382568\n",
      "Epoch 128: perda treino: 6.036647796630859\n",
      "Epoch 129: perda treino: 5.962492942810059\n",
      "Epoch 130: perda treino: 5.8930439949035645\n",
      "Epoch 131: perda treino: 5.826928615570068\n",
      "Epoch 132: perda treino: 5.763526916503906\n",
      "Epoch 133: perda treino: 5.701467514038086\n",
      "Epoch 134: perda treino: 5.639211654663086\n",
      "Epoch 135: perda treino: 5.576217174530029\n",
      "Epoch 136: perda treino: 5.5128254890441895\n",
      "Epoch 137: perda treino: 5.4498982429504395\n",
      "Epoch 138: perda treino: 5.388664722442627\n",
      "Epoch 139: perda treino: 5.329354286193848\n",
      "Epoch 140: perda treino: 5.272482872009277\n",
      "Epoch 141: perda treino: 5.218995094299316\n",
      "Epoch 142: perda treino: 5.168452739715576\n",
      "Epoch 143: perda treino: 5.1202263832092285\n",
      "Epoch 144: perda treino: 5.074419975280762\n",
      "Epoch 145: perda treino: 5.029926300048828\n",
      "Epoch 146: perda treino: 4.986224174499512\n",
      "Epoch 147: perda treino: 4.943007469177246\n",
      "Epoch 148: perda treino: 4.900461196899414\n",
      "Epoch 149: perda treino: 4.858709812164307\n",
      "Epoch 150: perda treino: 4.818124771118164\n",
      "Epoch 151: perda treino: 4.779359817504883\n",
      "Epoch 152: perda treino: 4.742271900177002\n",
      "Epoch 153: perda treino: 4.706851482391357\n",
      "Epoch 154: perda treino: 4.673050403594971\n",
      "Epoch 155: perda treino: 4.6408562660217285\n",
      "Epoch 156: perda treino: 4.610319137573242\n",
      "Epoch 157: perda treino: 4.580774784088135\n",
      "Epoch 158: perda treino: 4.55205774307251\n",
      "Epoch 159: perda treino: 4.524321556091309\n",
      "Epoch 160: perda treino: 4.497556686401367\n",
      "Epoch 161: perda treino: 4.471961498260498\n",
      "Epoch 162: perda treino: 4.447404384613037\n",
      "Epoch 163: perda treino: 4.4239115715026855\n",
      "Epoch 164: perda treino: 4.401484489440918\n",
      "Epoch 165: perda treino: 4.380062580108643\n",
      "Epoch 166: perda treino: 4.35947322845459\n",
      "Epoch 167: perda treino: 4.339639663696289\n",
      "Epoch 168: perda treino: 4.320437431335449\n",
      "Epoch 169: perda treino: 4.301840782165527\n",
      "Epoch 170: perda treino: 4.283927917480469\n",
      "Epoch 171: perda treino: 4.266669750213623\n",
      "Epoch 172: perda treino: 4.250068187713623\n",
      "Epoch 173: perda treino: 4.234130859375\n",
      "Epoch 174: perda treino: 4.2187933921813965\n",
      "Epoch 175: perda treino: 4.204041957855225\n",
      "Epoch 176: perda treino: 4.189870834350586\n",
      "Epoch 177: perda treino: 4.176318168640137\n",
      "Epoch 178: perda treino: 4.163260459899902\n",
      "Epoch 179: perda treino: 4.150666236877441\n",
      "Epoch 180: perda treino: 4.138511657714844\n",
      "Epoch 181: perda treino: 4.126783847808838\n",
      "Epoch 182: perda treino: 4.115542888641357\n",
      "Epoch 183: perda treino: 4.1049275398254395\n",
      "Epoch 184: perda treino: 4.094731330871582\n",
      "Epoch 185: perda treino: 4.084977626800537\n",
      "Epoch 186: perda treino: 4.075536251068115\n",
      "Epoch 187: perda treino: 4.06640625\n",
      "Epoch 188: perda treino: 4.0575995445251465\n",
      "Epoch 189: perda treino: 4.049084663391113\n",
      "Epoch 190: perda treino: 4.040853500366211\n",
      "Epoch 191: perda treino: 4.032881259918213\n",
      "Epoch 192: perda treino: 4.025144100189209\n",
      "Epoch 193: perda treino: 4.017632007598877\n",
      "Epoch 194: perda treino: 4.010339736938477\n",
      "Epoch 195: perda treino: 4.003240585327148\n",
      "Epoch 196: perda treino: 3.9963252544403076\n",
      "Epoch 197: perda treino: 3.989579916000366\n",
      "Epoch 198: perda treino: 3.983006477355957\n",
      "Epoch 199: perda treino: 3.976724147796631\n",
      "Epoch 200: perda treino: 3.969210386276245\n",
      "Epoch 201: perda treino: 3.9613962173461914\n",
      "Epoch 202: perda treino: 3.9529592990875244\n",
      "Epoch 203: perda treino: 3.9439523220062256\n",
      "Epoch 204: perda treino: 3.934666156768799\n",
      "Epoch 205: perda treino: 3.924926280975342\n",
      "Epoch 206: perda treino: 3.91473126411438\n",
      "Epoch 207: perda treino: 3.9032392501831055\n",
      "Epoch 208: perda treino: 3.8927221298217773\n",
      "Epoch 209: perda treino: 3.8819284439086914\n",
      "Epoch 210: perda treino: 3.8678371906280518\n",
      "Epoch 211: perda treino: 3.852215528488159\n",
      "Epoch 212: perda treino: 3.834399938583374\n",
      "Epoch 213: perda treino: 3.815194606781006\n",
      "Epoch 214: perda treino: 3.795088768005371\n",
      "Epoch 215: perda treino: 3.7767953872680664\n",
      "Epoch 216: perda treino: 3.7640421390533447\n",
      "Epoch 217: perda treino: 3.7550079822540283\n",
      "Epoch 218: perda treino: 3.748887538909912\n",
      "Epoch 219: perda treino: 3.7421412467956543\n",
      "Epoch 220: perda treino: 3.7337589263916016\n",
      "Epoch 221: perda treino: 3.723259687423706\n",
      "Epoch 222: perda treino: 3.7106480598449707\n",
      "Epoch 223: perda treino: 3.6962502002716064\n",
      "Epoch 224: perda treino: 3.6811208724975586\n",
      "Epoch 225: perda treino: 3.6665022373199463\n",
      "Epoch 226: perda treino: 3.653407335281372\n",
      "Epoch 227: perda treino: 3.6420023441314697\n",
      "Epoch 228: perda treino: 3.631551742553711\n",
      "Epoch 229: perda treino: 3.620936393737793\n",
      "Epoch 230: perda treino: 3.609927177429199\n",
      "Epoch 231: perda treino: 3.59873366355896\n",
      "Epoch 232: perda treino: 3.587341785430908\n",
      "Epoch 233: perda treino: 3.5758109092712402\n",
      "Epoch 234: perda treino: 3.5642106533050537\n",
      "Epoch 235: perda treino: 3.5526411533355713\n",
      "Epoch 236: perda treino: 3.541078567504883\n",
      "Epoch 237: perda treino: 3.529599189758301\n",
      "Epoch 238: perda treino: 3.518010139465332\n",
      "Epoch 239: perda treino: 3.506241798400879\n",
      "Epoch 240: perda treino: 3.4952030181884766\n",
      "Epoch 241: perda treino: 3.4845941066741943\n",
      "Epoch 242: perda treino: 3.4747421741485596\n",
      "Epoch 243: perda treino: 3.4653635025024414\n",
      "Epoch 244: perda treino: 3.456003427505493\n",
      "Epoch 245: perda treino: 3.446336269378662\n",
      "Epoch 246: perda treino: 3.436337471008301\n",
      "Epoch 247: perda treino: 3.425863742828369\n",
      "Epoch 248: perda treino: 3.4153804779052734\n",
      "Epoch 249: perda treino: 3.404923439025879\n",
      "Epoch 250: perda treino: 3.3947370052337646\n",
      "Epoch 251: perda treino: 3.3848440647125244\n",
      "Epoch 252: perda treino: 3.3751542568206787\n",
      "Epoch 253: perda treino: 3.365877628326416\n",
      "Epoch 254: perda treino: 3.356755256652832\n",
      "Epoch 255: perda treino: 3.347733974456787\n",
      "Epoch 256: perda treino: 3.338574171066284\n",
      "Epoch 257: perda treino: 3.3292226791381836\n",
      "Epoch 258: perda treino: 3.3197755813598633\n",
      "Epoch 259: perda treino: 3.310433864593506\n",
      "Epoch 260: perda treino: 3.3011410236358643\n",
      "Epoch 261: perda treino: 3.291877031326294\n",
      "Epoch 262: perda treino: 3.282630681991577\n",
      "Epoch 263: perda treino: 3.273582696914673\n",
      "Epoch 264: perda treino: 3.2646536827087402\n",
      "Epoch 265: perda treino: 3.2556655406951904\n",
      "Epoch 266: perda treino: 3.2466108798980713\n",
      "Epoch 267: perda treino: 3.2375056743621826\n",
      "Epoch 268: perda treino: 3.228327512741089\n",
      "Epoch 269: perda treino: 3.2190983295440674\n",
      "Epoch 270: perda treino: 3.2098405361175537\n",
      "Epoch 271: perda treino: 3.2005672454833984\n",
      "Epoch 272: perda treino: 3.1913251876831055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273: perda treino: 3.1822257041931152\n",
      "Epoch 274: perda treino: 3.173130989074707\n",
      "Epoch 275: perda treino: 3.1640374660491943\n",
      "Epoch 276: perda treino: 3.154911994934082\n",
      "Epoch 277: perda treino: 3.1456820964813232\n",
      "Epoch 278: perda treino: 3.1365904808044434\n",
      "Epoch 279: perda treino: 3.1276931762695312\n",
      "Epoch 280: perda treino: 3.118725061416626\n",
      "Epoch 281: perda treino: 3.1096863746643066\n",
      "Epoch 282: perda treino: 3.1006109714508057\n",
      "Epoch 283: perda treino: 3.0915544033050537\n",
      "Epoch 284: perda treino: 3.0825910568237305\n",
      "Epoch 285: perda treino: 3.073632001876831\n",
      "Epoch 286: perda treino: 3.0646326541900635\n",
      "Epoch 287: perda treino: 3.055626392364502\n",
      "Epoch 288: perda treino: 3.046830177307129\n",
      "Epoch 289: perda treino: 3.0381155014038086\n",
      "Epoch 290: perda treino: 3.029484272003174\n",
      "Epoch 291: perda treino: 3.0209133625030518\n",
      "Epoch 292: perda treino: 3.0123660564422607\n",
      "Epoch 293: perda treino: 3.0038225650787354\n",
      "Epoch 294: perda treino: 2.9952423572540283\n",
      "Epoch 295: perda treino: 2.986666440963745\n",
      "Epoch 296: perda treino: 2.9781572818756104\n",
      "Epoch 297: perda treino: 2.9697065353393555\n",
      "Epoch 298: perda treino: 2.9613120555877686\n",
      "Epoch 299: perda treino: 2.952958106994629\n",
      "Epoch 300: perda treino: 2.9446303844451904\n",
      "Epoch 301: perda treino: 2.9363229274749756\n",
      "Epoch 302: perda treino: 2.9280714988708496\n",
      "Epoch 303: perda treino: 2.9198825359344482\n",
      "Epoch 304: perda treino: 2.9117419719696045\n",
      "Epoch 305: perda treino: 2.9036576747894287\n",
      "Epoch 306: perda treino: 2.8956353664398193\n",
      "Epoch 307: perda treino: 2.887655019760132\n",
      "Epoch 308: perda treino: 2.879701852798462\n",
      "Epoch 309: perda treino: 2.8718156814575195\n",
      "Epoch 310: perda treino: 2.863983392715454\n",
      "Epoch 311: perda treino: 2.8562300205230713\n",
      "Epoch 312: perda treino: 2.84853458404541\n",
      "Epoch 313: perda treino: 2.840883255004883\n",
      "Epoch 314: perda treino: 2.833313226699829\n",
      "Epoch 315: perda treino: 2.825788736343384\n",
      "Epoch 316: perda treino: 2.818314552307129\n",
      "Epoch 317: perda treino: 2.810896873474121\n",
      "Epoch 318: perda treino: 2.803535223007202\n",
      "Epoch 319: perda treino: 2.796299934387207\n",
      "Epoch 320: perda treino: 2.7891387939453125\n",
      "Epoch 321: perda treino: 2.7820169925689697\n",
      "Epoch 322: perda treino: 2.7749807834625244\n",
      "Epoch 323: perda treino: 2.768007516860962\n",
      "Epoch 324: perda treino: 2.7610580921173096\n",
      "Epoch 325: perda treino: 2.754206657409668\n",
      "Epoch 326: perda treino: 2.7474021911621094\n",
      "Epoch 327: perda treino: 2.740663766860962\n",
      "Epoch 328: perda treino: 2.7339892387390137\n",
      "Epoch 329: perda treino: 2.727385997772217\n",
      "Epoch 330: perda treino: 2.7208447456359863\n",
      "Epoch 331: perda treino: 2.714353561401367\n",
      "Epoch 332: perda treino: 2.707929849624634\n",
      "Epoch 333: perda treino: 2.7015833854675293\n",
      "Epoch 334: perda treino: 2.6953036785125732\n",
      "Epoch 335: perda treino: 2.689089775085449\n",
      "Epoch 336: perda treino: 2.6829419136047363\n",
      "Epoch 337: perda treino: 2.676863670349121\n",
      "Epoch 338: perda treino: 2.670905828475952\n",
      "Epoch 339: perda treino: 2.6649510860443115\n",
      "Epoch 340: perda treino: 2.659043788909912\n",
      "Epoch 341: perda treino: 2.6532514095306396\n",
      "Epoch 342: perda treino: 2.6475071907043457\n",
      "Epoch 343: perda treino: 2.6417808532714844\n",
      "Epoch 344: perda treino: 2.6361613273620605\n",
      "Epoch 345: perda treino: 2.6307108402252197\n",
      "Epoch 346: perda treino: 2.6252784729003906\n",
      "Epoch 347: perda treino: 2.6198651790618896\n",
      "Epoch 348: perda treino: 2.6145825386047363\n",
      "Epoch 349: perda treino: 2.6093528270721436\n",
      "Epoch 350: perda treino: 2.604125499725342\n",
      "Epoch 351: perda treino: 2.5989885330200195\n",
      "Epoch 352: perda treino: 2.593946933746338\n",
      "Epoch 353: perda treino: 2.5889434814453125\n",
      "Epoch 354: perda treino: 2.5839693546295166\n",
      "Epoch 355: perda treino: 2.5790421962738037\n",
      "Epoch 356: perda treino: 2.574167251586914\n",
      "Epoch 357: perda treino: 2.569366931915283\n",
      "Epoch 358: perda treino: 2.564704656600952\n",
      "Epoch 359: perda treino: 2.5600316524505615\n",
      "Epoch 360: perda treino: 2.555440902709961\n",
      "Epoch 361: perda treino: 2.5508899688720703\n",
      "Epoch 362: perda treino: 2.546440839767456\n",
      "Epoch 363: perda treino: 2.5420610904693604\n",
      "Epoch 364: perda treino: 2.537726640701294\n",
      "Epoch 365: perda treino: 2.533444404602051\n",
      "Epoch 366: perda treino: 2.5292375087738037\n",
      "Epoch 367: perda treino: 2.5250649452209473\n",
      "Epoch 368: perda treino: 2.5210139751434326\n",
      "Epoch 369: perda treino: 2.517015218734741\n",
      "Epoch 370: perda treino: 2.5131008625030518\n",
      "Epoch 371: perda treino: 2.5092294216156006\n",
      "Epoch 372: perda treino: 2.5054097175598145\n",
      "Epoch 373: perda treino: 2.501692533493042\n",
      "Epoch 374: perda treino: 2.497997760772705\n",
      "Epoch 375: perda treino: 2.494353771209717\n",
      "Epoch 376: perda treino: 2.490774631500244\n",
      "Epoch 377: perda treino: 2.487247943878174\n",
      "Epoch 378: perda treino: 2.4837441444396973\n",
      "Epoch 379: perda treino: 2.4803645610809326\n",
      "Epoch 380: perda treino: 2.476963996887207\n",
      "Epoch 381: perda treino: 2.4736390113830566\n",
      "Epoch 382: perda treino: 2.4703736305236816\n",
      "Epoch 383: perda treino: 2.4671499729156494\n",
      "Epoch 384: perda treino: 2.4639880657196045\n",
      "Epoch 385: perda treino: 2.4609079360961914\n",
      "Epoch 386: perda treino: 2.4578046798706055\n",
      "Epoch 387: perda treino: 2.4548113346099854\n",
      "Epoch 388: perda treino: 2.4518396854400635\n",
      "Epoch 389: perda treino: 2.448892116546631\n",
      "Epoch 390: perda treino: 2.445977210998535\n",
      "Epoch 391: perda treino: 2.443106174468994\n",
      "Epoch 392: perda treino: 2.440406560897827\n",
      "Epoch 393: perda treino: 2.437751054763794\n",
      "Epoch 394: perda treino: 2.4350781440734863\n",
      "Epoch 395: perda treino: 2.432451009750366\n",
      "Epoch 396: perda treino: 2.429837465286255\n",
      "Epoch 397: perda treino: 2.4272451400756836\n",
      "Epoch 398: perda treino: 2.424678325653076\n",
      "Epoch 399: perda treino: 2.4221277236938477\n",
      "Epoch 400: perda treino: 2.4196040630340576\n",
      "Epoch 401: perda treino: 2.417093276977539\n",
      "Epoch 402: perda treino: 2.4145946502685547\n",
      "Epoch 403: perda treino: 2.4121150970458984\n",
      "Epoch 404: perda treino: 2.4096555709838867\n",
      "Epoch 405: perda treino: 2.407212972640991\n",
      "Epoch 406: perda treino: 2.4048707485198975\n",
      "Epoch 407: perda treino: 2.4025826454162598\n",
      "Epoch 408: perda treino: 2.4002928733825684\n",
      "Epoch 409: perda treino: 2.398017168045044\n",
      "Epoch 410: perda treino: 2.3957414627075195\n",
      "Epoch 411: perda treino: 2.3934667110443115\n",
      "Epoch 412: perda treino: 2.3911890983581543\n",
      "Epoch 413: perda treino: 2.388925552368164\n",
      "Epoch 414: perda treino: 2.3866922855377197\n",
      "Epoch 415: perda treino: 2.384542942047119\n",
      "Epoch 416: perda treino: 2.3823795318603516\n",
      "Epoch 417: perda treino: 2.380239725112915\n",
      "Epoch 418: perda treino: 2.3781116008758545\n",
      "Epoch 419: perda treino: 2.3759765625\n",
      "Epoch 420: perda treino: 2.3738560676574707\n",
      "Epoch 421: perda treino: 2.3717761039733887\n",
      "Epoch 422: perda treino: 2.3696963787078857\n",
      "Epoch 423: perda treino: 2.3676390647888184\n",
      "Epoch 424: perda treino: 2.3656013011932373\n",
      "Epoch 425: perda treino: 2.363562822341919\n",
      "Epoch 426: perda treino: 2.3615355491638184\n",
      "Epoch 427: perda treino: 2.3595516681671143\n",
      "Epoch 428: perda treino: 2.357557773590088\n",
      "Epoch 429: perda treino: 2.355553388595581\n",
      "Epoch 430: perda treino: 2.3535678386688232\n",
      "Epoch 431: perda treino: 2.3516039848327637\n",
      "Epoch 432: perda treino: 2.3496463298797607\n",
      "Epoch 433: perda treino: 2.3476908206939697\n",
      "Epoch 434: perda treino: 2.345735788345337\n",
      "Epoch 435: perda treino: 2.343820333480835\n",
      "Epoch 436: perda treino: 2.3419032096862793\n",
      "Epoch 437: perda treino: 2.3399693965911865\n",
      "Epoch 438: perda treino: 2.3380539417266846\n",
      "Epoch 439: perda treino: 2.336162567138672\n",
      "Epoch 440: perda treino: 2.334261655807495\n",
      "Epoch 441: perda treino: 2.3323657512664795\n",
      "Epoch 442: perda treino: 2.3304667472839355\n",
      "Epoch 443: perda treino: 2.3285839557647705\n",
      "Epoch 444: perda treino: 2.3266947269439697\n",
      "Epoch 445: perda treino: 2.324784278869629\n",
      "Epoch 446: perda treino: 2.322887897491455\n",
      "Epoch 447: perda treino: 2.3210084438323975\n",
      "Epoch 448: perda treino: 2.3191027641296387\n",
      "Epoch 449: perda treino: 2.3172338008880615\n",
      "Epoch 450: perda treino: 2.3153634071350098\n",
      "Epoch 451: perda treino: 2.3134758472442627\n",
      "Epoch 452: perda treino: 2.3115835189819336\n",
      "Epoch 453: perda treino: 2.309694528579712\n",
      "Epoch 454: perda treino: 2.307837724685669\n",
      "Epoch 455: perda treino: 2.305964946746826\n",
      "Epoch 456: perda treino: 2.3040759563446045\n",
      "Epoch 457: perda treino: 2.302210807800293\n",
      "Epoch 458: perda treino: 2.3003549575805664\n",
      "Epoch 459: perda treino: 2.29848575592041\n",
      "Epoch 460: perda treino: 2.2966251373291016\n",
      "Epoch 461: perda treino: 2.294762134552002\n",
      "Epoch 462: perda treino: 2.2928926944732666\n",
      "Epoch 463: perda treino: 2.291055202484131\n",
      "Epoch 464: perda treino: 2.2891361713409424\n",
      "Epoch 465: perda treino: 2.287080764770508\n",
      "Epoch 466: perda treino: 2.285062313079834\n",
      "Epoch 467: perda treino: 2.2830698490142822\n",
      "Epoch 468: perda treino: 2.2810680866241455\n",
      "Epoch 469: perda treino: 2.279029130935669\n",
      "Epoch 470: perda treino: 2.2769510746002197\n",
      "Epoch 471: perda treino: 2.2748656272888184\n",
      "Epoch 472: perda treino: 2.2728240489959717\n",
      "Epoch 473: perda treino: 2.270768165588379\n",
      "Epoch 474: perda treino: 2.2686920166015625\n",
      "Epoch 475: perda treino: 2.2666056156158447\n",
      "Epoch 476: perda treino: 2.2645010948181152\n",
      "Epoch 477: perda treino: 2.2623136043548584\n",
      "Epoch 478: perda treino: 2.2601091861724854\n",
      "Epoch 479: perda treino: 2.257896661758423\n",
      "Epoch 480: perda treino: 2.255659341812134\n",
      "Epoch 481: perda treino: 2.253429651260376\n",
      "Epoch 482: perda treino: 2.251190662384033\n",
      "Epoch 483: perda treino: 2.248938798904419\n",
      "Epoch 484: perda treino: 2.246703624725342\n",
      "Epoch 485: perda treino: 2.2444636821746826\n",
      "Epoch 486: perda treino: 2.2422473430633545\n",
      "Epoch 487: perda treino: 2.2400126457214355\n",
      "Epoch 488: perda treino: 2.237741708755493\n",
      "Epoch 489: perda treino: 2.2355430126190186\n",
      "Epoch 490: perda treino: 2.233603000640869\n",
      "Epoch 491: perda treino: 2.2316815853118896\n",
      "Epoch 492: perda treino: 2.2297680377960205\n",
      "Epoch 493: perda treino: 2.227778911590576\n",
      "Epoch 494: perda treino: 2.2258570194244385\n",
      "Epoch 495: perda treino: 2.2240185737609863\n",
      "Epoch 496: perda treino: 2.2221760749816895\n",
      "Epoch 497: perda treino: 2.2202908992767334\n",
      "Epoch 498: perda treino: 2.218379497528076\n",
      "Epoch 499: perda treino: 2.2164804935455322\n",
      "Epoch 500: perda treino: 2.2145655155181885\n",
      "Epoch 501: perda treino: 2.212636947631836\n",
      "Epoch 502: perda treino: 2.2107043266296387\n",
      "Epoch 503: perda treino: 2.208780288696289\n",
      "Epoch 504: perda treino: 2.20683217048645\n",
      "Epoch 505: perda treino: 2.204887866973877\n",
      "Epoch 506: perda treino: 2.2029786109924316\n",
      "Epoch 507: perda treino: 2.2010624408721924\n",
      "Epoch 508: perda treino: 2.1991796493530273\n",
      "Epoch 509: perda treino: 2.1973586082458496\n",
      "Epoch 510: perda treino: 2.1954734325408936\n",
      "Epoch 511: perda treino: 2.19358229637146\n",
      "Epoch 512: perda treino: 2.1917378902435303\n",
      "Epoch 513: perda treino: 2.1898481845855713\n",
      "Epoch 514: perda treino: 2.1880013942718506\n",
      "Epoch 515: perda treino: 2.186163902282715\n",
      "Epoch 516: perda treino: 2.1843323707580566\n",
      "Epoch 517: perda treino: 2.182513952255249\n",
      "Epoch 518: perda treino: 2.1807072162628174\n",
      "Epoch 519: perda treino: 2.178908109664917\n",
      "Epoch 520: perda treino: 2.177096128463745\n",
      "Epoch 521: perda treino: 2.1752777099609375\n",
      "Epoch 522: perda treino: 2.173474073410034\n",
      "Epoch 523: perda treino: 2.171753168106079\n",
      "Epoch 524: perda treino: 2.169884204864502\n",
      "Epoch 525: perda treino: 2.1681406497955322\n",
      "Epoch 526: perda treino: 2.1663782596588135\n",
      "Epoch 527: perda treino: 2.164576530456543\n",
      "Epoch 528: perda treino: 2.1627895832061768\n",
      "Epoch 529: perda treino: 2.161017656326294\n",
      "Epoch 530: perda treino: 2.159299612045288\n",
      "Epoch 531: perda treino: 2.157529592514038\n",
      "Epoch 532: perda treino: 2.1557528972625732\n",
      "Epoch 533: perda treino: 2.153978109359741\n",
      "Epoch 534: perda treino: 2.1522104740142822\n",
      "Epoch 535: perda treino: 2.1505720615386963\n",
      "Epoch 536: perda treino: 2.1487393379211426\n",
      "Epoch 537: perda treino: 2.1469953060150146\n",
      "Epoch 538: perda treino: 2.1452362537384033\n",
      "Epoch 539: perda treino: 2.1435225009918213\n",
      "Epoch 540: perda treino: 2.1417479515075684\n",
      "Epoch 541: perda treino: 2.14003586769104\n",
      "Epoch 542: perda treino: 2.1382646560668945\n",
      "Epoch 543: perda treino: 2.136549711227417\n",
      "Epoch 544: perda treino: 2.134775161743164\n",
      "Epoch 545: perda treino: 2.1330549716949463\n",
      "Epoch 546: perda treino: 2.1313464641571045\n",
      "Epoch 547: perda treino: 2.129547119140625\n",
      "Epoch 548: perda treino: 2.1277902126312256\n",
      "Epoch 549: perda treino: 2.1260573863983154\n",
      "Epoch 550: perda treino: 2.1243696212768555\n",
      "Epoch 551: perda treino: 2.1225428581237793\n",
      "Epoch 552: perda treino: 2.1207802295684814\n",
      "Epoch 553: perda treino: 2.119145154953003\n",
      "Epoch 554: perda treino: 2.117293357849121\n",
      "Epoch 555: perda treino: 2.115706205368042\n",
      "Epoch 556: perda treino: 2.1139018535614014\n",
      "Epoch 557: perda treino: 2.112041473388672\n",
      "Epoch 558: perda treino: 2.110358715057373\n",
      "Epoch 559: perda treino: 2.1085705757141113\n",
      "Epoch 560: perda treino: 2.1067209243774414\n",
      "Epoch 561: perda treino: 2.1050684452056885\n",
      "Epoch 562: perda treino: 2.1032958030700684\n",
      "Epoch 563: perda treino: 2.1014275550842285\n",
      "Epoch 564: perda treino: 2.099724531173706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565: perda treino: 2.097919225692749\n",
      "Epoch 566: perda treino: 2.0961031913757324\n",
      "Epoch 567: perda treino: 2.0943236351013184\n",
      "Epoch 568: perda treino: 2.092496156692505\n",
      "Epoch 569: perda treino: 2.090869188308716\n",
      "Epoch 570: perda treino: 2.089041233062744\n",
      "Epoch 571: perda treino: 2.087235927581787\n",
      "Epoch 572: perda treino: 2.085557222366333\n",
      "Epoch 573: perda treino: 2.083632469177246\n",
      "Epoch 574: perda treino: 2.081890821456909\n",
      "Epoch 575: perda treino: 2.080144166946411\n",
      "Epoch 576: perda treino: 2.0783824920654297\n",
      "Epoch 577: perda treino: 2.076580047607422\n",
      "Epoch 578: perda treino: 2.07479190826416\n",
      "Epoch 579: perda treino: 2.0730180740356445\n",
      "Epoch 580: perda treino: 2.071247100830078\n",
      "Epoch 581: perda treino: 2.0694353580474854\n",
      "Epoch 582: perda treino: 2.0677032470703125\n",
      "Epoch 583: perda treino: 2.0658998489379883\n",
      "Epoch 584: perda treino: 2.0643577575683594\n",
      "Epoch 585: perda treino: 2.062440872192383\n",
      "Epoch 586: perda treino: 2.060696840286255\n",
      "Epoch 587: perda treino: 2.058997631072998\n",
      "Epoch 588: perda treino: 2.057094097137451\n",
      "Epoch 589: perda treino: 2.0553677082061768\n",
      "Epoch 590: perda treino: 2.0535717010498047\n",
      "Epoch 591: perda treino: 2.0518486499786377\n",
      "Epoch 592: perda treino: 2.0500290393829346\n",
      "Epoch 593: perda treino: 2.0483341217041016\n",
      "Epoch 594: perda treino: 2.0465781688690186\n",
      "Epoch 595: perda treino: 2.044719934463501\n",
      "Epoch 596: perda treino: 2.0430567264556885\n",
      "Epoch 597: perda treino: 2.041278123855591\n",
      "Epoch 598: perda treino: 2.0393497943878174\n",
      "Epoch 599: perda treino: 2.0377776622772217\n",
      "Epoch 600: perda treino: 2.036074161529541\n",
      "Epoch 601: perda treino: 2.0341403484344482\n",
      "Epoch 602: perda treino: 2.032311201095581\n",
      "Epoch 603: perda treino: 2.030620813369751\n",
      "Epoch 604: perda treino: 2.028709650039673\n",
      "Epoch 605: perda treino: 2.027045726776123\n",
      "Epoch 606: perda treino: 2.0254032611846924\n",
      "Epoch 607: perda treino: 2.0234131813049316\n",
      "Epoch 608: perda treino: 2.021756887435913\n",
      "Epoch 609: perda treino: 2.0200181007385254\n",
      "Epoch 610: perda treino: 2.0180978775024414\n",
      "Epoch 611: perda treino: 2.0164384841918945\n",
      "Epoch 612: perda treino: 2.014700412750244\n",
      "Epoch 613: perda treino: 2.012894630432129\n",
      "Epoch 614: perda treino: 2.0111162662506104\n",
      "Epoch 615: perda treino: 2.009350061416626\n",
      "Epoch 616: perda treino: 2.007610559463501\n",
      "Epoch 617: perda treino: 2.005897283554077\n",
      "Epoch 618: perda treino: 2.0041706562042236\n",
      "Epoch 619: perda treino: 2.00236177444458\n",
      "Epoch 620: perda treino: 2.0006065368652344\n",
      "Epoch 621: perda treino: 1.9988244771957397\n",
      "Epoch 622: perda treino: 1.9971423149108887\n",
      "Epoch 623: perda treino: 1.9954646825790405\n",
      "Epoch 624: perda treino: 1.9936707019805908\n",
      "Epoch 625: perda treino: 1.9919252395629883\n",
      "Epoch 626: perda treino: 1.9901525974273682\n",
      "Epoch 627: perda treino: 1.9884848594665527\n",
      "Epoch 628: perda treino: 1.9867719411849976\n",
      "Epoch 629: perda treino: 1.9849225282669067\n",
      "Epoch 630: perda treino: 1.9832288026809692\n",
      "Epoch 631: perda treino: 1.9814679622650146\n",
      "Epoch 632: perda treino: 1.9796491861343384\n",
      "Epoch 633: perda treino: 1.9779449701309204\n",
      "Epoch 634: perda treino: 1.9761334657669067\n",
      "Epoch 635: perda treino: 1.9744081497192383\n",
      "Epoch 636: perda treino: 1.9726980924606323\n",
      "Epoch 637: perda treino: 1.9709054231643677\n",
      "Epoch 638: perda treino: 1.9692795276641846\n",
      "Epoch 639: perda treino: 1.9675225019454956\n",
      "Epoch 640: perda treino: 1.9656416177749634\n",
      "Epoch 641: perda treino: 1.9639095067977905\n",
      "Epoch 642: perda treino: 1.962165355682373\n",
      "Epoch 643: perda treino: 1.9604254961013794\n",
      "Epoch 644: perda treino: 1.9586528539657593\n",
      "Epoch 645: perda treino: 1.9569512605667114\n",
      "Epoch 646: perda treino: 1.9551030397415161\n",
      "Epoch 647: perda treino: 1.9533404111862183\n",
      "Epoch 648: perda treino: 1.9515882730484009\n",
      "Epoch 649: perda treino: 1.9498212337493896\n",
      "Epoch 650: perda treino: 1.9480490684509277\n",
      "Epoch 651: perda treino: 1.9463764429092407\n",
      "Epoch 652: perda treino: 1.9445537328720093\n",
      "Epoch 653: perda treino: 1.9428327083587646\n",
      "Epoch 654: perda treino: 1.9410723447799683\n",
      "Epoch 655: perda treino: 1.9392634630203247\n",
      "Epoch 656: perda treino: 1.9375115633010864\n",
      "Epoch 657: perda treino: 1.9357413053512573\n",
      "Epoch 658: perda treino: 1.9339501857757568\n",
      "Epoch 659: perda treino: 1.9322335720062256\n",
      "Epoch 660: perda treino: 1.930445909500122\n",
      "Epoch 661: perda treino: 1.9286586046218872\n",
      "Epoch 662: perda treino: 1.9268746376037598\n",
      "Epoch 663: perda treino: 1.9251759052276611\n",
      "Epoch 664: perda treino: 1.9233967065811157\n",
      "Epoch 665: perda treino: 1.9215580224990845\n",
      "Epoch 666: perda treino: 1.9197797775268555\n",
      "Epoch 667: perda treino: 1.9181110858917236\n",
      "Epoch 668: perda treino: 1.9162800312042236\n",
      "Epoch 669: perda treino: 1.9145678281784058\n",
      "Epoch 670: perda treino: 1.9128365516662598\n",
      "Epoch 671: perda treino: 1.9109283685684204\n",
      "Epoch 672: perda treino: 1.9093459844589233\n",
      "Epoch 673: perda treino: 1.9075627326965332\n",
      "Epoch 674: perda treino: 1.9055999517440796\n",
      "Epoch 675: perda treino: 1.9038894176483154\n",
      "Epoch 676: perda treino: 1.9020659923553467\n",
      "Epoch 677: perda treino: 1.9002803564071655\n",
      "Epoch 678: perda treino: 1.898561954498291\n",
      "Epoch 679: perda treino: 1.8967043161392212\n",
      "Epoch 680: perda treino: 1.89492666721344\n",
      "Epoch 681: perda treino: 1.8931889533996582\n",
      "Epoch 682: perda treino: 1.8913652896881104\n",
      "Epoch 683: perda treino: 1.889683485031128\n",
      "Epoch 684: perda treino: 1.8879196643829346\n",
      "Epoch 685: perda treino: 1.886009931564331\n",
      "Epoch 686: perda treino: 1.8844090700149536\n",
      "Epoch 687: perda treino: 1.8825483322143555\n",
      "Epoch 688: perda treino: 1.8806928396224976\n",
      "Epoch 689: perda treino: 1.8789958953857422\n",
      "Epoch 690: perda treino: 1.8771216869354248\n",
      "Epoch 691: perda treino: 1.875451922416687\n",
      "Epoch 692: perda treino: 1.87368905544281\n",
      "Epoch 693: perda treino: 1.8717464208602905\n",
      "Epoch 694: perda treino: 1.8701213598251343\n",
      "Epoch 695: perda treino: 1.8683340549468994\n",
      "Epoch 696: perda treino: 1.8663020133972168\n",
      "Epoch 697: perda treino: 1.864802360534668\n",
      "Epoch 698: perda treino: 1.863002061843872\n",
      "Epoch 699: perda treino: 1.8609344959259033\n",
      "Epoch 700: perda treino: 1.8592416048049927\n",
      "Epoch 701: perda treino: 1.8573634624481201\n",
      "Epoch 702: perda treino: 1.855596661567688\n",
      "Epoch 703: perda treino: 1.8538655042648315\n",
      "Epoch 704: perda treino: 1.8519387245178223\n",
      "Epoch 705: perda treino: 1.850281834602356\n",
      "Epoch 706: perda treino: 1.848502278327942\n",
      "Epoch 707: perda treino: 1.8464665412902832\n",
      "Epoch 708: perda treino: 1.8450322151184082\n",
      "Epoch 709: perda treino: 1.8432586193084717\n",
      "Epoch 710: perda treino: 1.8405879735946655\n",
      "Epoch 711: perda treino: 1.8385807275772095\n",
      "Epoch 712: perda treino: 1.8361790180206299\n",
      "Epoch 713: perda treino: 1.8332107067108154\n",
      "Epoch 714: perda treino: 1.8307229280471802\n",
      "Epoch 715: perda treino: 1.828162670135498\n",
      "Epoch 716: perda treino: 1.825221061706543\n",
      "Epoch 717: perda treino: 1.8228098154067993\n",
      "Epoch 718: perda treino: 1.8207181692123413\n",
      "Epoch 719: perda treino: 1.8182777166366577\n",
      "Epoch 720: perda treino: 1.8160637617111206\n",
      "Epoch 721: perda treino: 1.8139386177062988\n",
      "Epoch 722: perda treino: 1.8115437030792236\n",
      "Epoch 723: perda treino: 1.809459924697876\n",
      "Epoch 724: perda treino: 1.8073623180389404\n",
      "Epoch 725: perda treino: 1.8049781322479248\n",
      "Epoch 726: perda treino: 1.8029426336288452\n",
      "Epoch 727: perda treino: 1.8007481098175049\n",
      "Epoch 728: perda treino: 1.7984898090362549\n",
      "Epoch 729: perda treino: 1.7964526414871216\n",
      "Epoch 730: perda treino: 1.794177532196045\n",
      "Epoch 731: perda treino: 1.7921160459518433\n",
      "Epoch 732: perda treino: 1.7899855375289917\n",
      "Epoch 733: perda treino: 1.7877507209777832\n",
      "Epoch 734: perda treino: 1.7856675386428833\n",
      "Epoch 735: perda treino: 1.783484697341919\n",
      "Epoch 736: perda treino: 1.781406283378601\n",
      "Epoch 737: perda treino: 1.779333472251892\n",
      "Epoch 738: perda treino: 1.7771611213684082\n",
      "Epoch 739: perda treino: 1.775089979171753\n",
      "Epoch 740: perda treino: 1.773073673248291\n",
      "Epoch 741: perda treino: 1.7709261178970337\n",
      "Epoch 742: perda treino: 1.7690374851226807\n",
      "Epoch 743: perda treino: 1.7669215202331543\n",
      "Epoch 744: perda treino: 1.7647191286087036\n",
      "Epoch 745: perda treino: 1.762678623199463\n",
      "Epoch 746: perda treino: 1.7605904340744019\n",
      "Epoch 747: perda treino: 1.7586132287979126\n",
      "Epoch 748: perda treino: 1.7566179037094116\n",
      "Epoch 749: perda treino: 1.7546181678771973\n",
      "Epoch 750: perda treino: 1.752619743347168\n",
      "Epoch 751: perda treino: 1.7505916357040405\n",
      "Epoch 752: perda treino: 1.748565673828125\n",
      "Epoch 753: perda treino: 1.7465397119522095\n",
      "Epoch 754: perda treino: 1.7445828914642334\n",
      "Epoch 755: perda treino: 1.7425081729888916\n",
      "Epoch 756: perda treino: 1.740638256072998\n",
      "Epoch 757: perda treino: 1.73857843875885\n",
      "Epoch 758: perda treino: 1.7365994453430176\n",
      "Epoch 759: perda treino: 1.7345695495605469\n",
      "Epoch 760: perda treino: 1.732514500617981\n",
      "Epoch 761: perda treino: 1.7305127382278442\n",
      "Epoch 762: perda treino: 1.7285125255584717\n",
      "Epoch 763: perda treino: 1.726511836051941\n",
      "Epoch 764: perda treino: 1.7245084047317505\n",
      "Epoch 765: perda treino: 1.722475528717041\n",
      "Epoch 766: perda treino: 1.7205631732940674\n",
      "Epoch 767: perda treino: 1.718496322631836\n",
      "Epoch 768: perda treino: 1.716521978378296\n",
      "Epoch 769: perda treino: 1.714491367340088\n",
      "Epoch 770: perda treino: 1.7125433683395386\n",
      "Epoch 771: perda treino: 1.710545539855957\n",
      "Epoch 772: perda treino: 1.7084932327270508\n",
      "Epoch 773: perda treino: 1.7064279317855835\n",
      "Epoch 774: perda treino: 1.704445481300354\n",
      "Epoch 775: perda treino: 1.7024691104888916\n",
      "Epoch 776: perda treino: 1.7004481554031372\n",
      "Epoch 777: perda treino: 1.6985501050949097\n",
      "Epoch 778: perda treino: 1.6964830160140991\n",
      "Epoch 779: perda treino: 1.6946479082107544\n",
      "Epoch 780: perda treino: 1.6925692558288574\n",
      "Epoch 781: perda treino: 1.690697193145752\n",
      "Epoch 782: perda treino: 1.6886467933654785\n",
      "Epoch 783: perda treino: 1.6866538524627686\n",
      "Epoch 784: perda treino: 1.6846624612808228\n",
      "Epoch 785: perda treino: 1.6825238466262817\n",
      "Epoch 786: perda treino: 1.6806367635726929\n",
      "Epoch 787: perda treino: 1.6784889698028564\n",
      "Epoch 788: perda treino: 1.6765280961990356\n",
      "Epoch 789: perda treino: 1.6745370626449585\n",
      "Epoch 790: perda treino: 1.6725757122039795\n",
      "Epoch 791: perda treino: 1.670547604560852\n",
      "Epoch 792: perda treino: 1.6684584617614746\n",
      "Epoch 793: perda treino: 1.6664639711380005\n",
      "Epoch 794: perda treino: 1.664555549621582\n",
      "Epoch 795: perda treino: 1.6624946594238281\n",
      "Epoch 796: perda treino: 1.6606249809265137\n",
      "Epoch 797: perda treino: 1.6585222482681274\n",
      "Epoch 798: perda treino: 1.6565454006195068\n",
      "Epoch 799: perda treino: 1.6545835733413696\n",
      "Epoch 800: perda treino: 1.6525720357894897\n",
      "Epoch 801: perda treino: 1.6505658626556396\n",
      "Epoch 802: perda treino: 1.6486142873764038\n",
      "Epoch 803: perda treino: 1.64653480052948\n",
      "Epoch 804: perda treino: 1.644762635231018\n",
      "Epoch 805: perda treino: 1.6426465511322021\n",
      "Epoch 806: perda treino: 1.6407591104507446\n",
      "Epoch 807: perda treino: 1.6388599872589111\n",
      "Epoch 808: perda treino: 1.6366714239120483\n",
      "Epoch 809: perda treino: 1.6347023248672485\n",
      "Epoch 810: perda treino: 1.6327388286590576\n",
      "Epoch 811: perda treino: 1.6307690143585205\n",
      "Epoch 812: perda treino: 1.6287347078323364\n",
      "Epoch 813: perda treino: 1.626734733581543\n",
      "Epoch 814: perda treino: 1.6246880292892456\n",
      "Epoch 815: perda treino: 1.6228185892105103\n",
      "Epoch 816: perda treino: 1.6206952333450317\n",
      "Epoch 817: perda treino: 1.618920922279358\n",
      "Epoch 818: perda treino: 1.6167712211608887\n",
      "Epoch 819: perda treino: 1.6149572134017944\n",
      "Epoch 820: perda treino: 1.6129800081253052\n",
      "Epoch 821: perda treino: 1.6107608079910278\n",
      "Epoch 822: perda treino: 1.6092982292175293\n",
      "Epoch 823: perda treino: 1.607107162475586\n",
      "Epoch 824: perda treino: 1.6048756837844849\n",
      "Epoch 825: perda treino: 1.6030731201171875\n",
      "Epoch 826: perda treino: 1.6007596254348755\n",
      "Epoch 827: perda treino: 1.5992488861083984\n",
      "Epoch 828: perda treino: 1.5972957611083984\n",
      "Epoch 829: perda treino: 1.5949701070785522\n",
      "Epoch 830: perda treino: 1.5934007167816162\n",
      "Epoch 831: perda treino: 1.5907864570617676\n",
      "Epoch 832: perda treino: 1.5893704891204834\n",
      "Epoch 833: perda treino: 1.586998701095581\n",
      "Epoch 834: perda treino: 1.5848809480667114\n",
      "Epoch 835: perda treino: 1.5830152034759521\n",
      "Epoch 836: perda treino: 1.580704927444458\n",
      "Epoch 837: perda treino: 1.5788410902023315\n",
      "Epoch 838: perda treino: 1.5767067670822144\n",
      "Epoch 839: perda treino: 1.5748924016952515\n",
      "Epoch 840: perda treino: 1.5727589130401611\n",
      "Epoch 841: perda treino: 1.5709261894226074\n",
      "Epoch 842: perda treino: 1.5688438415527344\n",
      "Epoch 843: perda treino: 1.5668225288391113\n",
      "Epoch 844: perda treino: 1.5648696422576904\n",
      "Epoch 845: perda treino: 1.5626953840255737\n",
      "Epoch 846: perda treino: 1.5610181093215942\n",
      "Epoch 847: perda treino: 1.5587997436523438\n",
      "Epoch 848: perda treino: 1.556821346282959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 849: perda treino: 1.5548489093780518\n",
      "Epoch 850: perda treino: 1.5524042844772339\n",
      "Epoch 851: perda treino: 1.5505642890930176\n",
      "Epoch 852: perda treino: 1.54849374294281\n",
      "Epoch 853: perda treino: 1.5461033582687378\n",
      "Epoch 854: perda treino: 1.544543743133545\n",
      "Epoch 855: perda treino: 1.542296051979065\n",
      "Epoch 856: perda treino: 1.5400575399398804\n",
      "Epoch 857: perda treino: 1.538207769393921\n",
      "Epoch 858: perda treino: 1.5358186960220337\n",
      "Epoch 859: perda treino: 1.5337845087051392\n",
      "Epoch 860: perda treino: 1.5317012071609497\n",
      "Epoch 861: perda treino: 1.5295473337173462\n",
      "Epoch 862: perda treino: 1.5274298191070557\n",
      "Epoch 863: perda treino: 1.5253798961639404\n",
      "Epoch 864: perda treino: 1.5232614278793335\n",
      "Epoch 865: perda treino: 1.5211340188980103\n",
      "Epoch 866: perda treino: 1.5191247463226318\n",
      "Epoch 867: perda treino: 1.5170037746429443\n",
      "Epoch 868: perda treino: 1.515082836151123\n",
      "Epoch 869: perda treino: 1.5128681659698486\n",
      "Epoch 870: perda treino: 1.5109831094741821\n",
      "Epoch 871: perda treino: 1.5086867809295654\n",
      "Epoch 872: perda treino: 1.5070240497589111\n",
      "Epoch 873: perda treino: 1.5046906471252441\n",
      "Epoch 874: perda treino: 1.5025684833526611\n",
      "Epoch 875: perda treino: 1.5006808042526245\n",
      "Epoch 876: perda treino: 1.4983773231506348\n",
      "Epoch 877: perda treino: 1.4966604709625244\n",
      "Epoch 878: perda treino: 1.4941483736038208\n",
      "Epoch 879: perda treino: 1.4920891523361206\n",
      "Epoch 880: perda treino: 1.4900240898132324\n",
      "Epoch 881: perda treino: 1.4877829551696777\n",
      "Epoch 882: perda treino: 1.4858933687210083\n",
      "Epoch 883: perda treino: 1.483647346496582\n",
      "Epoch 884: perda treino: 1.481451392173767\n",
      "Epoch 885: perda treino: 1.4793437719345093\n",
      "Epoch 886: perda treino: 1.4773420095443726\n",
      "Epoch 887: perda treino: 1.4752610921859741\n",
      "Epoch 888: perda treino: 1.473022222518921\n",
      "Epoch 889: perda treino: 1.4709346294403076\n",
      "Epoch 890: perda treino: 1.4688386917114258\n",
      "Epoch 891: perda treino: 1.4667247533798218\n",
      "Epoch 892: perda treino: 1.4646036624908447\n",
      "Epoch 893: perda treino: 1.462523102760315\n",
      "Epoch 894: perda treino: 1.4603742361068726\n",
      "Epoch 895: perda treino: 1.4582278728485107\n",
      "Epoch 896: perda treino: 1.4561595916748047\n",
      "Epoch 897: perda treino: 1.4539662599563599\n",
      "Epoch 898: perda treino: 1.452177882194519\n",
      "Epoch 899: perda treino: 1.449950098991394\n",
      "Epoch 900: perda treino: 1.4480453729629517\n",
      "Epoch 901: perda treino: 1.4456899166107178\n",
      "Epoch 902: perda treino: 1.443857192993164\n",
      "Epoch 903: perda treino: 1.441432237625122\n",
      "Epoch 904: perda treino: 1.4394334554672241\n",
      "Epoch 905: perda treino: 1.4371603727340698\n",
      "Epoch 906: perda treino: 1.4353890419006348\n",
      "Epoch 907: perda treino: 1.432953953742981\n",
      "Epoch 908: perda treino: 1.4309008121490479\n",
      "Epoch 909: perda treino: 1.4286768436431885\n",
      "Epoch 910: perda treino: 1.4266743659973145\n",
      "Epoch 911: perda treino: 1.4248796701431274\n",
      "Epoch 912: perda treino: 1.4226659536361694\n",
      "Epoch 913: perda treino: 1.4201985597610474\n",
      "Epoch 914: perda treino: 1.4185855388641357\n",
      "Epoch 915: perda treino: 1.4162172079086304\n",
      "Epoch 916: perda treino: 1.4143284559249878\n",
      "Epoch 917: perda treino: 1.4118165969848633\n",
      "Epoch 918: perda treino: 1.4098848104476929\n",
      "Epoch 919: perda treino: 1.4076038599014282\n",
      "Epoch 920: perda treino: 1.4056838750839233\n",
      "Epoch 921: perda treino: 1.4035546779632568\n",
      "Epoch 922: perda treino: 1.4012880325317383\n",
      "Epoch 923: perda treino: 1.3991671800613403\n",
      "Epoch 924: perda treino: 1.3975123167037964\n",
      "Epoch 925: perda treino: 1.395217776298523\n",
      "Epoch 926: perda treino: 1.393649697303772\n",
      "Epoch 927: perda treino: 1.3907885551452637\n",
      "Epoch 928: perda treino: 1.3895928859710693\n",
      "Epoch 929: perda treino: 1.3866500854492188\n",
      "Epoch 930: perda treino: 1.3855787515640259\n",
      "Epoch 931: perda treino: 1.3837577104568481\n",
      "Epoch 932: perda treino: 1.3802942037582397\n",
      "Epoch 933: perda treino: 1.3796614408493042\n",
      "Epoch 934: perda treino: 1.3763741254806519\n",
      "Epoch 935: perda treino: 1.3751839399337769\n",
      "Epoch 936: perda treino: 1.3740613460540771\n",
      "Epoch 937: perda treino: 1.3703696727752686\n",
      "Epoch 938: perda treino: 1.3682076930999756\n",
      "Epoch 939: perda treino: 1.367704153060913\n",
      "Epoch 940: perda treino: 1.3632583618164062\n",
      "Epoch 941: perda treino: 1.3623507022857666\n",
      "Epoch 942: perda treino: 1.3602129220962524\n",
      "Epoch 943: perda treino: 1.3568899631500244\n",
      "Epoch 944: perda treino: 1.3555008172988892\n",
      "Epoch 945: perda treino: 1.3526506423950195\n",
      "Epoch 946: perda treino: 1.3506155014038086\n",
      "Epoch 947: perda treino: 1.3488408327102661\n",
      "Epoch 948: perda treino: 1.3462568521499634\n",
      "Epoch 949: perda treino: 1.3439147472381592\n",
      "Epoch 950: perda treino: 1.3427082300186157\n",
      "Epoch 951: perda treino: 1.3396530151367188\n",
      "Epoch 952: perda treino: 1.3381690979003906\n",
      "Epoch 953: perda treino: 1.3357396125793457\n",
      "Epoch 954: perda treino: 1.333275556564331\n",
      "Epoch 955: perda treino: 1.3309108018875122\n",
      "Epoch 956: perda treino: 1.3291786909103394\n",
      "Epoch 957: perda treino: 1.3268842697143555\n",
      "Epoch 958: perda treino: 1.3252137899398804\n",
      "Epoch 959: perda treino: 1.3225821256637573\n",
      "Epoch 960: perda treino: 1.3205727338790894\n",
      "Epoch 961: perda treino: 1.3185046911239624\n",
      "Epoch 962: perda treino: 1.3165240287780762\n",
      "Epoch 963: perda treino: 1.314435362815857\n",
      "Epoch 964: perda treino: 1.3122769594192505\n",
      "Epoch 965: perda treino: 1.3101370334625244\n",
      "Epoch 966: perda treino: 1.3081516027450562\n",
      "Epoch 967: perda treino: 1.306159257888794\n",
      "Epoch 968: perda treino: 1.303784728050232\n",
      "Epoch 969: perda treino: 1.302330493927002\n",
      "Epoch 970: perda treino: 1.299666404724121\n",
      "Epoch 971: perda treino: 1.2979052066802979\n",
      "Epoch 972: perda treino: 1.295292854309082\n",
      "Epoch 973: perda treino: 1.293276309967041\n",
      "Epoch 974: perda treino: 1.291222333908081\n",
      "Epoch 975: perda treino: 1.2889474630355835\n",
      "Epoch 976: perda treino: 1.2871025800704956\n",
      "Epoch 977: perda treino: 1.284969687461853\n",
      "Epoch 978: perda treino: 1.2828598022460938\n",
      "Epoch 979: perda treino: 1.2807071208953857\n",
      "Epoch 980: perda treino: 1.2784298658370972\n",
      "Epoch 981: perda treino: 1.2762559652328491\n",
      "Epoch 982: perda treino: 1.2743399143218994\n",
      "Epoch 983: perda treino: 1.271904706954956\n",
      "Epoch 984: perda treino: 1.270263433456421\n",
      "Epoch 985: perda treino: 1.2676737308502197\n",
      "Epoch 986: perda treino: 1.265447735786438\n",
      "Epoch 987: perda treino: 1.2631161212921143\n",
      "Epoch 988: perda treino: 1.2610716819763184\n",
      "Epoch 989: perda treino: 1.258962631225586\n",
      "Epoch 990: perda treino: 1.2563140392303467\n",
      "Epoch 991: perda treino: 1.2550326585769653\n",
      "Epoch 992: perda treino: 1.251853346824646\n",
      "Epoch 993: perda treino: 1.2500007152557373\n",
      "Epoch 994: perda treino: 1.2474074363708496\n",
      "Epoch 995: perda treino: 1.2454167604446411\n",
      "Epoch 996: perda treino: 1.2430568933486938\n",
      "Epoch 997: perda treino: 1.2407625913619995\n",
      "Epoch 998: perda treino: 1.2384545803070068\n",
      "Epoch 999: perda treino: 1.236140251159668\n",
      "Teste - perda depois do treinamento 1.810560941696167\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(X_teste.shape)\n",
    "y_pred = model(X_teste)\n",
    "antes_treino = criterion(y_pred, y_teste) \n",
    "print('Teste - perda antes do treinamento' , antes_treino.item())\n",
    "\n",
    "\n",
    "#-----------------Treinamento\n",
    "model.train()\n",
    "epoch = 1000\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    \n",
    "    #Explicitamente configura os gradientes em zero\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Passe Forward\n",
    "    y_pred = model(X_treino)\n",
    "    \n",
    "    # Computa a perda\n",
    "    loss = criterion(y_pred, y_treino)\n",
    "    \n",
    "    print('Epoch {}: perda treino: {}'.format(epoch, loss.item()))\n",
    "    \n",
    "    # Propaga os erros (backpropagation) e atualiza os pesos\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "    \n",
    "#-----------------Avaliação\n",
    "model.eval()\n",
    "\n",
    "y_pred = model(X_teste)\n",
    "after_train = criterion(y_pred, y_teste) \n",
    "print('Teste - perda depois do treinamento' , after_train.item())    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
